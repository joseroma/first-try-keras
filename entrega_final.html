<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jose Rodriguez Maldonado" />


<title>Práctica 1: Analisis de parametros para redes neuronales profundas en KERAS</title>

<script src="entrega_final_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="entrega_final_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="entrega_final_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="entrega_final_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="entrega_final_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="entrega_final_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="entrega_final_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="entrega_final_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="entrega_final_files/navigation-1.1/tabsets.js"></script>
<script src="entrega_final_files/navigation-1.1/codefolding.js"></script>
<link href="entrega_final_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="entrega_final_files/highlightjs-9.12.0/highlight.js"></script>
<script src="entrega_final_files/kePrint-0.0.1/kePrint.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Práctica 1: Analisis de parametros para redes neuronales profundas en KERAS</h1>
<h4 class="author"><em>Jose Rodriguez Maldonado</em></h4>
<h4 class="date"><em>Octubre de 2018</em></h4>

</div>


<p><strong>NOTA IMPORTANTE</strong>: Algunas gráficas pueden no haberse cargado bien. Si refresca la página en el punto que te encuentres, deberás mantenerte en el mismo sitio y la gráfica te deberá aparecerte correctamente. Un saludo.</p>
<div id="introduccion" class="section level1">
<h1>Introducción</h1>
<p>Esta primera práctica se va a dividir en dos partes.</p>
<p>Para la primera parte, se probaran diferentes combinaciones de parámetros y cómo afectan al modelo.</p>
<p>En la segunda parte, se hará lo mismo para un conjunto de variables seleccionadas del set de datos <strong>Breast Cancer</strong>. Se harán diferentes prubas sobre las posibles capas que podemos llegar a introducir y los parámetros que podemos probar. Finalmente, se compararan los resultados obtenidos por el modelo de DeepLearning con los obtenidos para los diferentes algoritmos de Machine Learning del año pasado.</p>
</div>
<div id="mnist" class="section level1">
<h1>MNIST</h1>
<div id="que-vamos-a-hacer" class="section level2">
<h2>¿Qué vamos a hacer?</h2>
<p>Para esta práctica se probarán las siguientes variables sobre el modelo de <em>Deep Learning</em>.</p>
<ul>
<li><strong>Numero de capas interas</strong> del modelo</li>
<li><strong>Numero de neuronas</strong> para cada capa del modelo</li>
<li>Valor de <strong>dropout</strong></li>
</ul>
</div>
<div id="codigo" class="section level2">
<h2>Codigo</h2>
<div id="recopilar-datos" class="section level3">
<h3>Recopilar datos</h3>
<p>Esta parte es igual que la que podemos encontrar en el tutorial sobre cómo utilizar keras visto en clase.</p>
<pre class="r"><code>library(keras)
mnist &lt;- dataset_mnist()  
x_train &lt;- mnist$train$x
y_train &lt;- mnist$train$y 
x_test &lt;- mnist$test$x
y_test &lt;- mnist$test$y

x_train&lt;-array_reshape(x_train, c(nrow(x_train),784))
x_test&lt;-array_reshape(x_test, c(nrow(x_test),784))

x_train &lt;- x_train / 255
x_test &lt;- x_test / 255

y_train &lt;- to_categorical(y_train, 10)
y_test &lt;- to_categorical(y_test, 10)</code></pre>
</div>
<div id="numero-de-capas-y-de-neuronas" class="section level3">
<h3>Numero de capas y de neuronas</h3>
<p>Vamos a probar los siguientes valores:</p>
<pre class="r"><code>second_layer = c(1400, 700, 300, 50, 40, 30 , 20 ,15)
third_layer = c(784, 400, 130, 30, 25 , 20 , 15 , 10)
fourth_layer = c(784, 600, 400, 200, 150 , 80 , 60 , 20)
fifth_layer = c(256, 150, 80, 30, 25 , 20 , 15 , 10)
sixth_layer = c(150, 160, 100, 70, 60, 50, 40, 30 )
df &lt;- data.frame(  l2=second_layer, l3=third_layer, l4=fourth_layer, l5= fifth_layer , l6=sixth_layer)

dropout = c(0.3,0.3,0.3,0.3,0.3, 0.3, 0.3, 0.3)
nnet_comb&lt;-c(2,5,7)</code></pre>
<p>Estos datos estan ajustados para poder ver:</p>
<ul>
<li>Que ocurre si las neuronas de una red son mayores que el número de entradas.</li>
<li>¿Entrena la red mejor disminuyendo el numero de neuronas por capa gradualmente?</li>
<li>¿Cómo afecta aumentar o disminuir el número de capas?</li>
</ul>
<p>En total tenemos 15 combinaciones de parámetros: 5 configuraciones de neuronas y 3 número de capas. En mi ordenador el tiempo que puede tardar en probar todas estas combinaciones oscila entre los 24-25 minutos.</p>
<p>Para probar estos parámetros he utilizado las siguientes funciones:</p>
<pre class="r"><code>calcula_modelo&lt;-function(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test, num_capas=2, vector=c(256,180), drop.out=c(0.4,0.3), activation_func ){
  t &lt;- proc.time() # Inicia el cronómetro
  modelo &lt;- keras_model_sequential()
  i&lt;-1
  while(i&lt;num_capas+1){
    if(i==1){
    modelo %&gt;% 
        layer_dense(units = as.integer(vector[i]), activation = &quot;relu&quot;, input_shape = c(784)) %&gt;% 
        layer_dropout(rate = drop.out[[i]]) 
      i&lt;-i+1
    }else{
    modelo %&gt;%
      layer_dense(units = as.integer(vector[i]), activation = &quot;relu&quot;, input_shape = c(784)) %&gt;% 
        layer_dropout(rate = drop.out[[i]]) 
      i&lt;-i+1
    }
  }
  
  modelo %&gt;%
    layer_dense(units = 10, activation = activation_func)
  
  modelo %&gt;% compile(
    loss = &quot;categorical_crossentropy&quot;,
    optimizer = optimizer_rmsprop(),
    metrics = c(&quot;accuracy&quot;))
  
  #Repetir solo el FIT
  train_data&lt;-modelo %&gt;% fit(
    x_train, y_train, epochs = 10, batch_size = 128, view_metrics = FALSE, 
    validation_split = 0.2)
  
  var&lt;-modelo %&gt;% evaluate(x_test, y_test,verbose = 0)

  proc.time()-t  
  
  return(c(var$acc,var$loss, train_data$metrics$acc[10], train_data$metrics$loss[10], t[&quot;elapsed&quot;]))
}


aplicar_dif_layers_lapply_prep&lt;-function(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test,num_comb=c(2,3,4),df=df, j, dropout, activation_func=&#39;softmax&#39;){
  resul&lt;-c()
  if(lengths(df)[1] != 1 &amp;&amp; lengths(dropout)[1] != 1){
    resul&lt;-&quot;POR PROBLEMAS DE COMP. NO VOT A PROBAR DROPS Y DF A LA VEZ&quot;
  }else{
   
    if(lengths(df)[1] != 1){
      print(&quot;NNET COMB&quot;)
      resul&lt;-c(unlist(lapply(1:length(num_comb), function(p) calcula_modelo(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test,num_comb[p],vector=df[,j], drop.out = dropout, activation_func))))
    }
    if(lengths(dropout)[1] != 1){
      vect_drop&lt;-c()
      print(&quot;DROP COMB&quot;)
      for(m in 1:length(dropout)){
        vect_drop&lt;-c(vect_drop, dropout[[m]][j])
      }
      resul&lt;-c(unlist(lapply(1:length(num_comb), function(p) calcula_modelo(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test,num_comb[p],vector=df, drop.out = vect_drop, activation_func))))
    }
  }
  return(resul)
}

resultado_lapply&lt;-as.matrix(lapply(1:length(df), function(i) aplicar_dif_layers_lapply_prep(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test,nnet_comb,df, i, dropout)))

data_frame&lt;-data.frame(t(matrix(unlist(lapply(1:length(df), function(i) resultado_lapply[i])), nrow = 5*length(nnet_comb) )))

nombres_data_frame&lt;-c()
for (e in 1:length(nnet_comb)) {
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;ACC&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;LOSS&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TRAIN_ACC&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TRAIN_LOSS&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TIEMPO&quot;,e, sep=&quot;&quot;))
}
colnames(data_frame)&lt;-nombres_data_frame</code></pre>
</div>
</div>
<div id="resultados" class="section level2">
<h2>Resultados</h2>
<p>Se representan los datos para tratar de ver con mas claridad los resultados obtenidos.</p>
<div id="capas-y-combinaciones-de-neuronas" class="section level3">
<h3>Capas y combinaciones de neuronas</h3>
<pre class="r"><code>axx &lt;- list(
  gridcolor=&#39;rgb(255, 255, 255)&#39;,
  zerolinecolor=&#39;rgb(255, 255, 255)&#39;,
  showbackground=TRUE,
  backgroundcolor=&#39;rgb(230, 230,230)&#39;
)

plot_acc_3 &lt;- plot_ly(showscale = FALSE, scene=&#39;scene100&#39;) %&gt;%
  add_surface(z = ~acc_values_3, opacity=0.98) %&gt;%
  add_surface(z = ~acc_values_val_3, opacity=0.85, colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))

plot_loss_3 &lt;- plot_ly(showscale = FALSE, scene=&#39;scene200&#39;) %&gt;%
  add_surface(z = ~loss_values_3, opacity=0.98) %&gt;%
  add_surface(z = ~loss_values_val_3, opacity=0.85, colorscale = list(c(0,&quot;rgb(107,184,214)&quot;),c(1,&quot;rgb(0,90,124)&quot;)))

plot_acc_2 &lt;- plot_ly(showscale = FALSE, scene=&#39;scene300&#39;) %&gt;%
  add_surface(z = ~acc_values_2, opacity=0.98) %&gt;%
  add_surface(z = ~acc_values_val_2, opacity=0.85, colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))

plot_loss_2 &lt;- plot_ly(showscale = FALSE, scene=&#39;scene400&#39;) %&gt;%
  add_surface(z = ~loss_values_2, opacity=0.98) %&gt;%
  add_surface(z = ~loss_values_val_2, opacity=0.85, colorscale = list(c(0,&quot;rgb(107,184,214)&quot;),c(1,&quot;rgb(0,90,124)&quot;)))






three_layers&lt;-subplot(plot_acc_3, plot_loss_3)%&gt;%
  layout(title = &quot;3D Subplots ACC &amp; LOSS&quot;,
         scene100 = list(domain=list(x=c(0,0.5),y=c(0.25,0.75)),
                      xaxis=axx, yaxis=axx, zaxis=axx,
                      aspectmode=&#39;cube&#39;),
         scene200 = list(domain=list(x=c(0.51,1),y=c(0.25,0.75)),
                       xaxis=axx, yaxis=axx, zaxis=axx,
                       aspectmode=&#39;cube&#39;))

two_layers&lt;-subplot(plot_acc_2, plot_loss_2)%&gt;%
  layout(title = &quot;3D Subplots ACC &amp; LOSS&quot;,
         scene300 = list(domain=list(x=c(0,0.5),y=c(0.25,0.75)),
                      xaxis=axx, yaxis=axx, zaxis=axx,
                      aspectmode=&#39;cube&#39;),
         scene400 = list(domain=list(x=c(0.51,1),y=c(0.25,0.75)),
                       xaxis=axx, yaxis=axx, zaxis=axx,
                       aspectmode=&#39;cube&#39;))

capas.tres&lt;- api_create(three_layers, filename=&quot;3 Layers COMB&quot;)
capas.dos&lt;- api_create(two_layers, filename=&quot;2 Layers COMB&quot;)</code></pre>
<pre class="r"><code>capas.tres</code></pre>
<iframe src="https://plot.ly/~Pedroroma/163.embed" width="800" height="600" id="igraph" scrolling="no" seamless="seamless" frameBorder="0">
</iframe>
<p>En estas gráficas podemos ver de un color naranja-rojo-rosa los valores obtenidos para el train. Mientras que los obtenidos para el test estan de un color Morado-Azul-Verde-Amarillo. A la izquierda podemos ver el ACC y a la derecha el LOSS. En el eje X tenemos las diferentes combinaciones de neuronas que hemos probado. Ej, el valor cero en la gráfica corresponde con el primer numero de neuronas que se ha probado. Mientras que para el eje y tenemos las diferentes combinaciones de neuronas que hemos usado para cada capa. Ej. para y= 0 en x=0 tenemos 2 capas, la primera y una interna que tendrás como valores 1400 y 700 respectivamente. Y finalmente, el eje z se corresponde con los valores de ACC y LOSS para cada caso.</p>
<p>Los resultados empeoran conforme vamos aumentando el número de capas. Especialmente, vamos a tener peores resultados cuando tenemos mas capas con pequeño número de neuronas por capa. Pero no podemos sacar mas información, a si que voy a quitar de la gráfica los resultados de tener 8 capas. Para poder apreciar mas claramente la diferencia entre el resto de resultados.</p>
<pre class="r"><code>capas.dos</code></pre>
<iframe src="https://plot.ly/~Pedroroma/165.embed" width="800" height="600" id="igraph" scrolling="no" seamless="seamless" frameBorder="0">
</iframe>
<ul>
<li>Que ocurre si las neuronas de una red son mayores que el número de entradas.</li>
<li>¿Cómo afecta aumentar o disminuir el número de capas?</li>
</ul>
<p>Para un número de capas de neuronas <strong>bajo</strong> con <strong>alto</strong> numero de neuronas por capa obtenemos mejores resultados.</p>
<p>Pero para valores <strong>altos</strong> de <em>neuronas por capa</em>, la diferencia entre el ACC de entrenamiento y el ACC de test aumenta considerablemente. Esto es indicativo de <strong>overfitting</strong>.</p>
<p>Este overfitting se va <strong>reduciendo</strong></p>
<ul>
<li>conforme <strong>aumenta</strong> el número de capas, manteniendo altos numero de neuronas</li>
<li>conforme <strong>disminuye</strong> número de neuronas por capa .</li>
</ul>
<p>Para un bajo número de neuronas por capa se aprecia que el <em>acc </em>de <strong>train</strong> <em>disminye</em> mucho mas que el <em>acc</em> de <strong>test</strong>. Esto podría ser indicativo de <strong>underfitting</strong>.</p>
<p>Podemos estar ante un caso en el que, por no haber tenido suficiente tiempo para entrenar; el modelo no halla podido aprender los patrones relevantes que necesita de los datos de train.</p>
<p>Aunque para este caso parece ser mas razonable pensar que esta situación se produzca como consecuencia del aumento del LOSS. Se nota como crece conforme aumentamos el número de capas.</p>
<ul>
<li>¿Entrena la red mejor disminuyendo el numero de neuronas por capa gradualmente?</li>
</ul>
<p>Si comparamos un caso de este tipo tenemos que fijarnos concretamente en Y=1(descenso brusco) y Y=2(descenso gradual).</p>
<p>Para ambos casos se nota que el ACC de train es mucho mayor para bajo numero de capas neuronales. Lo que es indicativo de un ligero <strong>overfitting</strong>, pero este overfitting parece estar provocado por el número de neuronas . Esta diferencia se disminuye conforme aumentamos el número de capas neuronales. Como se ha <strong>comentado ya anteriormente</strong>.</p>
<p>Se nota que para altos numeros de capas neuronales (es cuando se puede apreciar las diferencias en el descenso), ofrece peores resultados un descenso brusco de las capas neuronales, que un descenso gradual. Como nos indican los valores de ACC correspondientes. Esto podría ser debido a que el modelo al tener un mayor número de capas con bajo número de neuronas por capa “mezcla” los patrones que aprende provocando que aprenda peor de los datos.</p>
</div>
<div id="dropout" class="section level3">
<h3>Dropout</h3>
<p>Para el dropout vamos a probar las siguientes combinaciones:</p>
<pre class="r"><code>dropout_1&lt;-seq(0.1, 0.9, by=0.2)
drop1&lt;-c()
drop2&lt;-c()
cont&lt;-0
for(i in 1:length(dropout_1)){
    for(j in 1:length(dropout_1)){
      drop1&lt;-c(drop1,dropout_1[i])
      drop2&lt;-c(drop2,dropout_1[j])
      cont&lt;-cont+1
    }
}
drop_comb&lt;-list(drop1,drop2)

nnet_comb_num = c(784, 600, 400, 200)
nnet_comb&lt;-c(rep(2, length(dropout_1)))</code></pre>
<p>He decidido escoger Volviendo a ejecutar la función anterior podemos probar las diferentes cofiguraciones.</p>
<pre class="r"><code>resultado_lapply&lt;-as.matrix(lapply(1:length(df), function(i) aplicar_dif_layers_lapply_prep((x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test,nnet_comb,df = nnet_comb_num, i, drop_values)))


drop.data.frame&lt;-data.frame(t(matrix(unlist(lapply(1:length(df), function(i) resultado_lapply[i])), nrow = 5*length(nnet_comb) )))

nombres_data_frame&lt;-c()
for (e in 1:length(nnet_comb)) {
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;ACC&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;LOSS&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TRAIN_ACC&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TRAIN_LOSS&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TIEMPO&quot;,e, sep=&quot;&quot;))
}
colnames(drop.data.frame)&lt;-nombres_data_frame</code></pre>
<p>Pasamos a plotear los resultados obtenidos:</p>
<pre class="r"><code>plot_acc &lt;- plot_ly(showscale = FALSE, scene=&#39;scene10&#39;) %&gt;%
  add_surface(z = ~drop_acc_values, opacity=0.98) %&gt;%
  add_surface(z = ~drop_acc_values_val, opacity=0.85, colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))

plot_loss &lt;- plot_ly(showscale = FALSE, scene=&#39;scene20&#39;) %&gt;%
  add_surface(z = ~drop_loss_values, opacity=0.98) %&gt;%
  add_surface(z = ~drop_loss_values_val, opacity=0.85, colorscale = list(c(0,&quot;rgb(107,184,214)&quot;),c(1,&quot;rgb(0,90,124)&quot;)))

drop_scenario&lt;-subplot(plot_acc, plot_loss)%&gt;%
  layout(title = &quot;3D Subplots ACC &amp; LOSS&quot;,
         scene10 = list(domain=list(x=c(0,0.5),y=c(0.25,0.75)),
                      xaxis=axx, yaxis=axx, zaxis=axx,
                      aspectmode=&#39;cube&#39;),
         scene20 = list(domain=list(x=c(0.51,1),y=c(0.25,0.75)),
                       xaxis=axx, yaxis=axx, zaxis=axx,
                       aspectmode=&#39;cube&#39;))

capas.dos &lt;- api_create(drop_scenario, filename=&quot;ACC and LOSS DROPOUT&quot;)</code></pre>
<pre class="r"><code>capas.dos</code></pre>
<iframe src="https://plot.ly/~Pedroroma/167.embed" width="800" height="600" id="igraph" scrolling="no" seamless="seamless" frameBorder="0">
</iframe>
<p>Al igual que antes podemos encontrar a la izquierda los diferentes valores para el ACC (Rosa-TRAIN, AZUL-Test). Y a la derecha los valores para el LOSS. en ‘X’ la el dropout usado por la capa incial y en ‘y’ el dropout usado por la primera capa interna.</p>
<p>Se puede apreciar que para el dropout de la capa incial apenas vamos a notar cambios independiente de cual sea. Mientras que para el dropout de la capa interna si que podemos notar como el acc de train va disminuyendo gradualmente conforme aumentamos el dropout. Además de aumentar el loss, al eliminar algunos patrones que había aprendido el modelo de mas. Acercando los valores de ACC para train y test, y por consiguiente el <strong>overfitting</strong>. Diría que el mejor valor que le podríamos asignar al loss se encuentra en esa franja en la que el ACC de test se pone amarillo (asciende muy muy levemente) mientras que el ACC de train disminuye (disminuyendo el <strong>overfitting</strong>).</p>
</div>
</div>
</div>
<div id="datos-hospital-breast-cancer" class="section level1">
<h1>Datos hospital (Breast cancer)</h1>
<div id="que-vamos-a-hacer-1" class="section level2">
<h2>¿Qué vamos a hacer?</h2>
<p>Para poder trabajar con todos estos datos, vamos a dividirlos. Una vez divididos se eligen para cada subconjunto las 8000 variables mas significativas, se descartan el resto. Habiendo realizado esta pequeña transformación ya tendremos un conjunto de datos con el que será muy fácil trabajar. Vamos a filtrar otra vez las variables que hemos obtenido anteriormente, para quedarnos solo con: 30, 200 y 800.</p>
<p>Tras unas pequeñas pruebas, he comprobado que el tiempo de cómputo necesario para este conjunto de datos es muhco menor que el que necesitabamos anteriormente. Esto me va a permitir añadir mas condiciones. Me parece muy interesante comprobar cuanto se afectan los datos en función de las variables que hemos seleccionado (30,200 y 800).</p>
<p>Además, se va a agrandar un poco mas el conjunto de pruebas que le vamos a hacer a estos datos. Al no tener muy clara que combinación podría resultar ser la mejor. Ampliar el rango de busqueda va a permitir poder ver para que valores se obtienen mejores resutlados, además de dar una idea general de que resultados podemos obtener con este modelo.</p>
</div>
<div id="leemos-los-datos" class="section level2">
<h2>Leemos los datos</h2>
<pre class="r"><code>test.set&lt;-read.csv(&quot;BreastCancer/BreastCancer/breastCancer_test.data&quot;, header=FALSE, sep=&#39;,&#39;)
train.set&lt;-read.csv(&quot;BreastCancer/BreastCancer/breastCancer_train.data&quot;, header=FALSE, sep=&#39;,&#39;)
data.names&lt;- read.csv(&quot;BreastCancer/BreastCancer/breastCancer.names&quot;)
all.data &lt;- rbind(train.set,test.set)

v.dependiente &lt;- &#39;relapse&#39;
colnames(train.set)[24482] &lt;-v.dependiente
colnames(test.set)[24482] &lt;-v.dependiente
colnames(all.data)[24482] &lt;-v.dependiente

train.set$relapse &lt;- ifelse(train.set$relapse == v.dependiente, 1, 0)
test.set$relapse &lt;- ifelse(test.set$relapse == v.dependiente, 1, 0)

#Pasamos a partir los datos

dim.train&lt;-dim(train.set)
dim.test&lt;-dim(test.set)
len_corte&lt;-round(dim.train[2]/2) 
part.1.train&lt;-train.set[,1:(len_corte-1)]
part.2.train&lt;-train.set[,len_corte:(dim.train[2]-1)]
part.1.test&lt;-test.set[,1:(len_corte-1)] 
part.2.test&lt;-test.set[,len_corte:(dim.test[2]-1)]
relapse.train&lt;-train.set[,24482]
relapse.test&lt;-test.set[,24482]

part.1.train&lt;-cbind.data.frame(part.1.train,relapse.train)
part.1.train&lt;-cbind.data.frame(part.1.train,relapse.train)
part.2.train&lt;-cbind.data.frame(part.2.train,relapse.train)
part.1.test&lt;-cbind.data.frame(part.1.test,relapse.test)
part.2.test&lt;-cbind.data.frame(part.2.test,relapse.test)

weight.var.1&lt;-information.gain(relapse.train~., part.1.train)
weight.var.2&lt;-information.gain(relapse.train~., part.2.train)
selected.var.1&lt;-cutoff.k(weight.var.1,8000)
selected.var.2&lt;-cutoff.k(weight.var.2,8000)
dataframe.1&lt;-part.1.train[,selected.var.1]
dataframe.2&lt;-part.2.train[,selected.var.2]

#Re-filtramos las variables obtenidas
train.set.reduced&lt;-cbind.data.frame(dataframe.1, dataframe.2)
weight.reduce.vars&lt;-information.gain(relapse.train~., train.set.reduced)
reduccion.30.var&lt;-cutoff.k(weight.reduce.vars,30)
reduccion.200.var&lt;-cutoff.k(weight.reduce.vars,200)
reduccion.800.var&lt;-cutoff.k(weight.reduce.vars,800)

reduced.train.30.var&lt;-train.set[,reduccion.30.var]
reduced.train.200.var&lt;-train.set[,reduccion.200.var]
reduced.train.800.var&lt;-train.set[,reduccion.800.var]
reduced.test.30.var&lt;-test.set[,reduccion.30.var]
reduced.test.200.var&lt;-test.set[,reduccion.200.var]
reduced.test.800.var&lt;-test.set[,reduccion.800.var]</code></pre>
</div>
<div id="combinaciones-seleccionadas" class="section level2">
<h2>Combinaciones seleccionadas</h2>
<p>Ahora pasamos a entrenar el modelo para todas estas posibles combinaciones.</p>
<pre class="r"><code>x_train_800&lt;- as.matrix(reduced.train.800.var)
x_test_800&lt;-as.matrix(reduced.test.800.var)
x_train_200&lt;- as.matrix(reduced.train.200.var)
x_test_200&lt;-as.matrix(reduced.test.200.var)
x_train_30&lt;- as.matrix(reduced.train.30.var)
x_test_30&lt;-as.matrix(reduced.test.30.var)
y_train&lt;-to_categorical(relapse.train,2)
y_test&lt;-to_categorical(relapse.test,2)

zero_layer = c(6000, 4000, 2800, 1000, 600 , 200 , 120 , 20)
first_layer = c(4000, 2500, 1800, 1000, 600 , 200 , 120 , 20)
second_layer = c(2000, 1200, 800, 500, 200 , 80 , 50 , 20)
third_layer = c(1000, 800, 600, 300, 100 , 80 , 30 , 20)
fourth_layer = c(800, 600, 400, 300, 200 , 120 , 70 , 20)
fifth_layer = c(700, 600, 500, 300, 200 , 120 , 70 , 50)
sixth_layer = c(200, 150, 80, 30, 25 , 20 , 15 , 10 )
seventh_layer = c(150, 100, 80, 50, 40 , 30 , 20 , 10 )
eigth_layer = c(120, 90, 70, 50, 40 , 30 , 15 , 10 )
ninth_layer = c(100, 80, 60, 50, 40 , 30 , 15 , 10 )
tenth_layer = c(80, 60, 50, 40, 30 , 20 , 15 , 10 )
dropout = c(0.3,0.3,0.3,0.3,0.3, 0.3, 0.3, 0.3)
nnet_comb&lt;-c(1,2,3,4,5,6,7)
df &lt;- data.frame( l0=zero_layer,l1=first_layer, l2=second_layer, l3=third_layer, 
                   l4=fourth_layer, l5= fifth_layer , l6=sixth_layer, l7=seventh_layer, l8=eigth_layer,
                   l9=ninth_layer, l10=tenth_layer)

resultado_lapply_800&lt;-as.matrix(lapply(1:length(df), function(i) aplicar_dif_layers_lapply_prep(x_train=x_train_800, x_test=x_test_800, y_train=y_train, y_test=y_test,nnet_comb,df, i, dropout, activation_func = &#39;sigmoid&#39;)))
resultado_lapply_200&lt;-as.matrix(lapply(1:length(df), function(i) aplicar_dif_layers_lapply_prep(x_train=x_train_200, x_test=x_test_200, y_train=y_train, y_test=y_test,nnet_comb,df, i, dropout, activation_func = &#39;sigmoid&#39;)))
resultado_lapply_30&lt;-as.matrix(lapply(1:length(df), function(i) aplicar_dif_layers_lapply_prep(x_train=x_train_30, x_test=x_test_30, y_train=y_train, y_test=y_test,nnet_comb,df, i, dropout, activation_func = &#39;sigmoid&#39;)))

drop.data.frame_800&lt;-data.frame(t(matrix(unlist(lapply(1:length(df), function(i) resultado_lapply_800[i])), nrow = 5*length(nnet_comb) )))
drop.data.frame_200&lt;-data.frame(t(matrix(unlist(lapply(1:length(df), function(i) resultado_lapply_200[i])), nrow = 5*length(nnet_comb) )))
drop.data.frame_30&lt;-data.frame(t(matrix(unlist(lapply(1:length(df), function(i) resultado_lapply_30[i])), nrow = 5*length(nnet_comb) )))

nombres_data_frame&lt;-c()
for (e in 1:length(nnet_comb)) {
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;ACC&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;LOSS&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TRAIN_ACC&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TRAIN_LOSS&quot;,e, sep=&quot;&quot;))
  nombres_data_frame &lt;- c(nombres_data_frame, paste(&quot;TIEMPO&quot;,e, sep=&quot;&quot;))
}
colnames(drop.data.frame_800)&lt;-nombres_data_frame
colnames(drop.data.frame_200)&lt;-nombres_data_frame
colnames(drop.data.frame_30)&lt;-nombres_data_frame</code></pre>
</div>
<div id="graficas" class="section level2">
<h2>Gráficas</h2>
<p>Se muestran a continuación los resutlados graficamente.</p>
<pre class="r"><code>library(plotly)

plot.acc.30&lt;-plot_ly(showscale = FALSE, scene=&#39;scene28&#39;) %&gt;%
  add_surface(z = ~acc.values.30, opacity=0.98) %&gt;%
  add_surface(z = ~acc.values.val.30, opacity=0.85, colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))

plot.acc.200&lt;-plot_ly(showscale = FALSE, scene=&#39;scene29&#39;) %&gt;%
  add_surface(z = ~acc.values.200, opacity=0.98)%&gt;%
  add_surface(z = ~acc.values.val.200, opacity=0.85,colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))

plot.acc.800&lt;-plot_ly(showscale = FALSE,scene=&#39;scene30&#39;) %&gt;%
  add_surface(z = ~acc.values.800, opacity=0.98) %&gt;%
  add_surface(z = ~acc.values.val.800, opacity=0.85, colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))


plot.loss.30 &lt;- plot_ly(showscale = FALSE,scene=&#39;scene31&#39;) %&gt;%
  add_surface(z = ~loss.values.30, opacity=0.98) %&gt;%
  add_surface(z = ~loss.values.val.30, opacity=0.85, colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))

plot.loss.200&lt;-plot_ly(showscale = FALSE,scene=&#39;scene32&#39;) %&gt;%
  add_surface(z = ~loss.values.200, opacity=0.98) %&gt;%
  add_surface(z = ~loss.values.val.200, opacity=0.85, colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))

plot.loss.800&lt;-plot_ly(showscale = FALSE,scene=&#39;scene33&#39;) %&gt;%
  add_surface(z = ~loss.values.800, opacity=0.98) %&gt;%
  add_surface(z = ~loss.values.val.800, opacity=0.85, colorscale = list(c(0,&quot;rgb(255,112,183)&quot;),c(1,&quot;rgb(128,0,64)&quot;)))

p.acc&lt;-subplot(plot.acc.30, plot.acc.200, plot.acc.800)%&gt;%
  layout(title = &quot;3D Subplots&quot;,
         scene28 = list(domain=list(x=c(0,0.35),y=c(0.25,0.75)),
                      xaxis=axx, yaxis=axx, zaxis=axx,
                      aspectmode=&#39;cube&#39;),
         scene29 = list(domain=list(x=c(0.35,0.6),y=c(0.25,0.75)),
                       xaxis=axx, yaxis=axx, zaxis=axx,
                       aspectmode=&#39;cube&#39;),
         scene30 = list(domain=list(x=c(0.6,1),y=c(0.25,0.75)),
                       xaxis=axx, yaxis=axx, zaxis=axx,
                       aspectmode=&#39;cube&#39;))

p.loss&lt;-subplot(plot.loss.30, plot.loss.200, plot.loss.800)%&gt;%
  layout(title = &quot;3D Subplots&quot;,
         scene31 = list(domain=list(x=c(0,0.35),y=c(0.25,0.75)),
                      xaxis=axx, yaxis=axx, zaxis=axx,
                      aspectmode=&#39;cube&#39;),
         scene32 = list(domain=list(x=c(0.35,0.6),y=c(0.25,0.75)),
                       xaxis=axx, yaxis=axx, zaxis=axx,
                       aspectmode=&#39;cube&#39;),
         scene33 = list(domain=list(x=c(0.6,1),y=c(0.25,0.75)),
                       xaxis=axx, yaxis=axx, zaxis=axx,
                       aspectmode=&#39;cube&#39;))

lung.plot.acc &lt;-api_create(p.acc, filename=&quot;LUNG PLOT ACC TRAIN TEST 1&quot;)

lung.plot.loss &lt;- api_create(p.loss, filename=&quot;LUNG PLOT LOSS TRAIN TEST 1&quot;)</code></pre>
<pre class="r"><code>lung.plot.acc</code></pre>
<iframe src="https://plot.ly/~Pedroroma/169.embed" width="800" height="600" id="igraph" scrolling="no" seamless="seamless" frameBorder="0">
</iframe>
<pre class="r"><code>lung.plot.loss</code></pre>
<iframe src="https://plot.ly/~Pedroroma/171.embed" width="800" height="600" id="igraph" scrolling="no" seamless="seamless" frameBorder="0">
</iframe>
<p>En estas gráficas se muestran todo igual que antes, la única diferencia es que aquí tenemos tres gráficas juntas. En este caso, de izquierda a derecha vamos a encontrar los resultados obtenidos para 30, 200 y 800 variables respectivamente. Arriba quedan los valores para el ACC y abajo los del LOSS.</p>
<p>Es muy dificil poder encontrar alguna clase de patrón como ocurria para el caso de MNIST.</p>
<p>Probamos a quitarles los valores de TRAIN para ver mejor la gráfica.</p>
<pre class="r"><code>lung.plot.accA</code></pre>
<iframe src="https://plot.ly/~Pedroroma/173.embed" width="800" height="600" id="igraph" scrolling="no" seamless="seamless" frameBorder="0">
</iframe>
<pre class="r"><code>lung.plot.lossA</code></pre>
<iframe src="https://plot.ly/~Pedroroma/175.embed" width="800" height="600" id="igraph" scrolling="no" seamless="seamless" frameBorder="0">
</iframe>
<p>Podemos apreciar un pequeño matiz al comprobar los datos resultantes, y es que:</p>
<ul>
<li>Para los datos con 30 variables, dificilmente vamos a obtener altos valores de ACC. Además, los valores mas altos tienen el ACC train bastante mas alto, indicando un claro <strong>overfitting</strong>.</li>
<li>Los valores con 800 variables tampoco llegan a tener altos valores para el ACC, y los pocos que tienen son valores de ACC mas grandes que los de train, por lo que no ofrece resultados que puedan interesarnos tampoco.</li>
<li>Pero en cambio, para los valores obtenidos con las 200 variables mas significativas si que encontramos valores de ACC interesantes.</li>
</ul>
<p>Concretamente, encontramos algunos resultados como:</p>
<pre class="r"><code>data.frame.new&lt;-data.frame(
  drop.data.frame_200$ACC1, 
  drop.data.frame_200$LOSS1, 
  drop.data.frame_200$TRAIN_ACC1,   drop.data.frame_200$TRAIN_LOSS1,
  drop.data.frame_200$TIEMPO1)
i&lt;-2
for(i in c(2,3,4,5,6,7)){
  data.temp&lt;-data.frame(
    drop.data.frame_200[paste(&quot;ACC&quot;, i,sep=&quot;&quot;)],
    drop.data.frame_200[paste(&quot;LOSS&quot;, i,sep=&quot;&quot;)],
    drop.data.frame_200[paste(&quot;TRAIN_ACC&quot;, i,sep=&quot;&quot;)],
    drop.data.frame_200[paste(&quot;TRAIN_LOSS&quot;, i,sep=&quot;&quot;)],
    drop.data.frame_200[paste(&quot;TIEMPO&quot;, i,sep=&quot;&quot;)])
  colnames(data.temp)&lt;-colnames(data.frame.new)
    data.frame.new&lt;-rbind(data.frame.new, data.temp)
    data.temp&lt;-0
    
}

ndx = order(data.frame.new$drop.data.frame_200.ACC1, decreasing=T)

data.order&lt;-data.frame.new[ndx,]
colnames(data.order)&lt;-c(&quot;ACC&quot;, &quot;LOSS&quot;, &quot;ACC_TRAIN&quot;, &quot;LOSS_TRAIN&quot;, &quot;TIEMPO&quot;)
kable(data.order[1:15,]) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)</code></pre>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
ACC
</th>
<th style="text-align:right;">
LOSS
</th>
<th style="text-align:right;">
ACC_TRAIN
</th>
<th style="text-align:right;">
LOSS_TRAIN
</th>
<th style="text-align:right;">
TIEMPO
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.5550810
</td>
<td style="text-align:right;">
0.9354839
</td>
<td style="text-align:right;">
0.3637690
</td>
<td style="text-align:right;">
838.37
</td>
</tr>
<tr>
<td style="text-align:left;">
13
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.7109697
</td>
<td style="text-align:right;">
0.9193549
</td>
<td style="text-align:right;">
0.1404125
</td>
<td style="text-align:right;">
776.51
</td>
</tr>
<tr>
<td style="text-align:left;">
17
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.5354006
</td>
<td style="text-align:right;">
0.9354839
</td>
<td style="text-align:right;">
0.2186846
</td>
<td style="text-align:right;">
886.11
</td>
</tr>
<tr>
<td style="text-align:left;">
30
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.6286543
</td>
<td style="text-align:right;">
0.7741935
</td>
<td style="text-align:right;">
0.8411464
</td>
<td style="text-align:right;">
944.54
</td>
</tr>
<tr>
<td style="text-align:left;">
37
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.5914872
</td>
<td style="text-align:right;">
0.8709677
</td>
<td style="text-align:right;">
0.2376435
</td>
<td style="text-align:right;">
846.06
</td>
</tr>
<tr>
<td style="text-align:left;">
43
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.6677599
</td>
<td style="text-align:right;">
0.7741935
</td>
<td style="text-align:right;">
0.8887084
</td>
<td style="text-align:right;">
1014.46
</td>
</tr>
<tr>
<td style="text-align:left;">
50
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.5904127
</td>
<td style="text-align:right;">
0.8870968
</td>
<td style="text-align:right;">
0.2342388
</td>
<td style="text-align:right;">
896.11
</td>
</tr>
<tr>
<td style="text-align:left;">
51
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.5888527
</td>
<td style="text-align:right;">
0.7419355
</td>
<td style="text-align:right;">
0.8168273
</td>
<td style="text-align:right;">
924.17
</td>
</tr>
<tr>
<td style="text-align:left;">
69
</td>
<td style="text-align:right;">
0.8947368
</td>
<td style="text-align:right;">
0.5493769
</td>
<td style="text-align:right;">
0.7419355
</td>
<td style="text-align:right;">
0.8387668
</td>
<td style="text-align:right;">
832.75
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
0.8421053
</td>
<td style="text-align:right;">
0.5556297
</td>
<td style="text-align:right;">
0.9193549
</td>
<td style="text-align:right;">
0.4829681
</td>
<td style="text-align:right;">
711.67
</td>
</tr>
<tr>
<td style="text-align:left;">
38
</td>
<td style="text-align:right;">
0.8421053
</td>
<td style="text-align:right;">
0.5835665
</td>
<td style="text-align:right;">
0.8870968
</td>
<td style="text-align:right;">
0.2790919
</td>
<td style="text-align:right;">
867.86
</td>
</tr>
<tr>
<td style="text-align:left;">
40
</td>
<td style="text-align:right;">
0.8421053
</td>
<td style="text-align:right;">
0.6071790
</td>
<td style="text-align:right;">
0.8064516
</td>
<td style="text-align:right;">
0.5569527
</td>
<td style="text-align:right;">
920.36
</td>
</tr>
<tr>
<td style="text-align:left;">
60
</td>
<td style="text-align:right;">
0.8421053
</td>
<td style="text-align:right;">
0.5986561
</td>
<td style="text-align:right;">
0.9193549
</td>
<td style="text-align:right;">
0.3358530
</td>
<td style="text-align:right;">
874.86
</td>
</tr>
<tr>
<td style="text-align:left;">
61
</td>
<td style="text-align:right;">
0.8421053
</td>
<td style="text-align:right;">
0.5323898
</td>
<td style="text-align:right;">
0.8225806
</td>
<td style="text-align:right;">
0.4248362
</td>
<td style="text-align:right;">
900.03
</td>
</tr>
<tr>
<td style="text-align:left;">
8
</td>
<td style="text-align:right;">
0.7894737
</td>
<td style="text-align:right;">
0.6196675
</td>
<td style="text-align:right;">
0.8548387
</td>
<td style="text-align:right;">
0.4932179
</td>
<td style="text-align:right;">
937.46
</td>
</tr>
</tbody>
</table>
<p>Aquí podemos ver algunos de los 15 mejores resultados obtenidos para 200 variables.</p>
</div>
<div id="cross-validation-auc" class="section level2">
<h2>10 Cross-Validation &amp; AUC</h2>
<p>Se va a usar la misma medida que utilizamos el año pasado para medir que tan bueno era un modelo. Para ello se ha reutilizado la función que habíamos utilizado anteriormente. Quedando tal que así:</p>
<pre class="r"><code>AUC &lt;-function(mod.estimado, last.col) {
  roc.curve &lt;-roc(last.col, mod.estimado, smooth=FALSE, auc=TRUE)
  auc.result &lt;-roc.curve$auc
  return(auc.result)
}


calcula_modelo&lt;-function(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test, num_capas=2, vector=c(256,180), drop.out=c(0.4,0.3), activation_func, k_folds=0 ){
  t &lt;- proc.time() # Inicia el cronómetro
  modelo &lt;- keras_model_sequential()
  i&lt;-1
  while(i&lt;num_capas+1){
    if(i==1){
      modelo %&gt;% 
        layer_dense(units = as.integer(vector[i]), activation = &quot;relu&quot;, input_shape = c(dim(x_train)[2])) %&gt;% 
        layer_dropout(rate = drop.out[[i]]) 
      i&lt;-i+1
    }else{
      modelo %&gt;%
        layer_dense(units = as.integer(vector[i]), activation = &quot;relu&quot;) %&gt;% 
        layer_dropout(rate = drop.out[[i]]) 
      i&lt;-i+1
    }
  }
  
  modelo %&gt;%
    layer_dense(units = ncol(y_train), activation = activation_func)
  
  modelo %&gt;% compile(
    loss = &quot;categorical_crossentropy&quot;,
    optimizer = optimizer_rmsprop(),
    metrics = c(&quot;accuracy&quot;))
  if(k_folds==0){
  train_data&lt;-modelo %&gt;% fit(x_train, y_train, epochs = 10, batch_size = 128, view_metrics = FALSE, 
                             validation_split = 0.2)
  var&lt;-modelo %&gt;% evaluate(test, y_test,verbose = 0)
  
  acc.train&lt;-train_data$metrics$acc[10]
  loss.train&lt;- train_data$metrics$loss[10]
  acc.test&lt;-var$acc
  loss.test&lt;-var$loss
  }else{
    all.data.data&lt;-rbind(x_train,x_test)
    all.data.relapse&lt;-rbind(y_train,y_test)
    cf&lt;-createFolds(all.data.relapse[,-1], k=k_folds)
    res.acc&lt;-c()
    res.loss&lt;-c()
    res.test.acc&lt;-c()
    res.test.loss&lt;-c()
    for(i in 1:k_folds) {
      test &lt;-as.matrix(all.data.data[unlist(cf[i]),])
      y_test &lt;-as.matrix(all.data.relapse[unlist(cf[i]),])
      train &lt;-as.matrix(all.data.data[-unlist(cf[i]),])
      y_train&lt;-as.matrix(all.data.relapse[-unlist(cf[i]),])
      resul&lt;-modelo %&gt;% fit(train, y_train, epochs = 10, batch_size = 128, view_metrics = FALSE, 
                                 validation_split = 0.2)
      res.acc&lt;-c(res.acc, resul$metrics$acc[10])
      res.loss&lt;-c(res.loss, resul$metrics$loss[10])
      #Predicted class
      predicted_clases&lt;-modelo %&gt;% predict_classes(test)
      #yhat_keras_class_vec &lt;- predict_classes(object = modelo, x = as.matrix(test)) %&gt;%
      #  as.vector()
      # Predicted Class Probability
      val.auc&lt;-AUC(predicted_clases,  y_test[,1])
      
      
      res.test.acc&lt;-c(res.test.acc, val.auc)
    }
    
    acc.train&lt;-mean(res.acc)
    loss.train&lt;-NaN
    acc.test&lt;-NaN
    loss.test&lt;-NaN
    
  }

  proc.time()-t  
  
  return(c(acc.train,loss.train, acc.test,loss.test, t[&quot;elapsed&quot;]))
}</code></pre>
<p>Utilizando estas funciones hemos obtenido los siguientes resultados:</p>
<pre class="r"><code>auc_val&lt;-matrix(unlist(lapply(1:7, function(i) drop.data.frame_200[paste(&quot;ACC&quot;,i,sep = &quot;&quot;)])))
dim(auc_val) &lt;- c(11, 7)
auc_plot&lt;-plot_ly(showscale = FALSE) %&gt;%
  add_surface(z = ~auc_val, opacity=0.98)

auc.surface = api_create(auc_plot, filename=&quot;AUC VAL&quot;)</code></pre>
<pre><code>## Found a grid already named: &#39;AUC VAL Grid&#39;. Since fileopt=&#39;overwrite&#39;, I&#39;ll try to update it</code></pre>
<pre><code>## Found a plot already named: &#39;AUC VAL&#39;. Since fileopt=&#39;overwrite&#39;, I&#39;ll try to update it</code></pre>
<pre class="r"><code>auc.surface</code></pre>
<iframe src="https://plot.ly/~Pedroroma/177.embed" width="800" height="600" id="igraph" scrolling="no" seamless="seamless" frameBorder="0">
</iframe>
<p>Los ejes utilizados para esta gráfica son los mismo que se han explicado anteriormente, de combinaciones de capas y de neuronas.</p>
<p>Se comprueba para el AUC que:</p>
<ul>
<li>Para los valores altos de capas neuronales los resultados son un tanto peores.</li>
<li>Se nota un leve parecido entre las gráficas de ACC y AUC. Pero, el AUC nos va a dar resultados mas claros a la hora de interpretar los resultados.</li>
<li>Los mejores resultados se obtienen para las primeras combinaciones de neuronas y pocas o muchas capas. Y conforme disminuimos el número de neuronas empezamos a obtener mejores resultados para valores intermedios de capas neuronales.</li>
</ul>
<pre class="r"><code>ndx = order(auc_val, decreasing=T)
ndx</code></pre>
<pre><code>##  [1] 36 50 58 56 23 68 37 54 43 52 53 67 62 12  2 33 65 46 57  8 51 35  1
## [24] 74 41 40 55 73  9 42 47 66 32 49 76  6 19 64 44 63 48 20 25 24 77 75
## [47] 70 29 61 21 22 15 28 27 38  3 17  4 69  5 18 26 10 30 11 31 72 34 71
## [70] 45 13 60 39 16  7 59 14</code></pre>
<pre class="r"><code>data.order&lt;-auc_val[ndx]

kable(data.order[1:10]) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)</code></pre>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
x
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.9681988
</td>
</tr>
<tr>
<td style="text-align:right;">
0.9596273
</td>
</tr>
<tr>
<td style="text-align:right;">
0.9333747
</td>
</tr>
<tr>
<td style="text-align:right;">
0.9189027
</td>
</tr>
<tr>
<td style="text-align:right;">
0.9133540
</td>
</tr>
<tr>
<td style="text-align:right;">
0.9039752
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8890476
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8643685
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8618012
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8483230
</td>
</tr>
</tbody>
</table>
<p>Aqui podemos ver los 10 mejores resultados de AUC obtenidos para este conjunto de datos.</p>
</div>
<div id="ml-caret" class="section level2">
<h2>ML-CARET</h2>
<p>A continuación recordamos los resultados que obtuvimos para los modelos utilizados el año pasado. Esta vez desde alto nivel utilizando el paquete CARET. Para ello se han usado las funciones implementadas el año pasado. No voy a entrar mucho en detalle, me voy a centrar mas en los resultados que se obtienen.</p>
<p>Vamos a coger de referencia la siguiente formula:</p>
<pre class="r"><code>formula</code></pre>
<pre><code>## relapse ~ V7704 + V19891 + V4937 + V13621 + V16856</code></pre>
<p>Esta formula la hemos obtenido seleccionando las 5 variables mas significativas que arroja FSelector. Obteniendo lo siguientes resultados:</p>
<pre class="r"><code>kable(tabla) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)</code></pre>
<table class="kable_wrapper table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td>
<table>
<thead>
<tr>
<th style="text-align:right;">
x
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.6887143
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table>
<thead>
<tr>
<th style="text-align:right;">
x
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.8853333
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table>
<thead>
<tr>
<th style="text-align:right;">
x
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.6868452
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table>
<thead>
<tr>
<th style="text-align:right;">
x
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.7152024
</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
<p>Aqui se muestran los resultados obtenidos para <strong>GLM</strong>, <strong>SVM</strong>, <strong>DT</strong> y <strong>NNET</strong> respectivamente.</p>
<p>Como podemos observar el AUC puede llegar, para esta pequeña demostración, a rondar 0.85 de AUC para el caso de <strong>SVM</strong>.</p>
</div>
<div id="conclusiones" class="section level2">
<h2>Conclusiones</h2>
<p>De cara a la conclusión final toca valorar los resultados obtenidos por nuestro modelo de Deep Learning. El mejor resultado de todas las combinaciones es de 0.96 de AUC, donde podemos notar que hay un poco de overfitting (Hay cierta diferencia significativa entre los ACC de train y test). Pero podemos llegar a obtener un AUC de en torno al 0.9 sin tener overfitting. Aunque han sido solo unas pocas combinaciones de entre todas las que hemos probado.</p>
<p>Por otro lado nos encontramos con los resultados que hemos obtenido sin apenas haber procesado los datos, solo cogiendo como formula las 5 variables mas significativas en la que fácilmente alcanzavamos un AUC de 0.88.</p>
<p>A la hora de ver los resultados no me parece una opción tan buena el haber usado <strong>Deep Learning</strong> para este conjunto de datos. Debido a que ha supuesto una gran dificultad mejorar levemente este accuracy, y podríamos haber obtenido iguales, o incluso mejores, resultados con otro modelo mas sencillo.</p>
<p>A diferencia de lo que ocurria para el caso de MNIST, donde se obtenían resultados soprendentemente buenos, en <em>Breast cancer</em> no tenemos suficientes datos como para poder utilizar un modelo tan complejo para clasificar los datos.</p>
<p>No solo en lo referente a resultado, sino también a rendimiento, un <em>modelo mas sencillo</em> parece la <strong>mejor opción</strong>. En lo que al <strong>tiempo y rendimiento</strong> respecta, mi ordenador ha sufrido al principio <em>estragos</em> para poder ejecutar las diferentes combinaciones que quería probar en MNIST. Estos problemas se han reducido sensiblemente al usar <strong>Breast cancer</strong>; debido a lo pequeño que se quedaba el dataframe tras procesarlo. He necesitado estar tomando medidas de tiempo para MNIST, aunque me han sido también muy útiles para <em>Breast cancer</em>. Desde descartar ejemplos que no me aportaban información, hacer estimaciones muy claras de cuanto podría tardar ‘x’ funcion en ejecutarse par una combinación, detección de errores …</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
